{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n",
      "(178, 13)\n",
      "(178,)\n",
      "[  1.42300000e+01   1.71000000e+00   2.43000000e+00   1.56000000e+01\n",
      "   1.27000000e+02   2.80000000e+00   3.06000000e+00   2.80000000e-01\n",
      "   2.29000000e+00   5.64000000e+00   1.04000000e+00   3.92000000e+00\n",
      "   1.06500000e+03]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# 了解数据\n",
    "wine = datasets.load_wine()\n",
    "print(wine.keys())\n",
    "print(wine.data.shape)\n",
    "print(wine.target.shape)\n",
    "print(wine.data[0])\n",
    "print(wine.target)\n",
    "print(wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13) (142,)\n"
     ]
    }
   ],
   "source": [
    "# 数据标准化处理\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "std_data = std.fit_transform(wine.data)\n",
    "# 划分数据集和测试机\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(std_data,wine.target,test_size=0.2)\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度： 0.964788732394\n",
      "测试集精度： 0.972222222222\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(x_train,y_train)\n",
    "print(\"训练集精度：\",knn.score(x_train,y_train))\n",
    "print(\"测试集精度：\",knn.score(x_test,y_test))\n",
    "print(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度： 0.950704225352\n",
      "测试集精度： 1.0\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=7, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=4,min_samples_leaf=7,random_state=0)\n",
    "dt.fit(x_train,y_train)\n",
    "print(\"训练集精度：\",dt.score(x_train,y_train))\n",
    "print(\"测试集精度：\",dt.score(x_test,y_test))\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 绘制决策树\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "import pydotplus\n",
    "from io import StringIO\n",
    "dot_data = StringIO()\n",
    "\n",
    "export_graphviz(dt, out_file=dot_data,  # 绘制决策树\n",
    "    feature_names=wine.feature_names,\n",
    "    class_names=wine.target_names,\n",
    "    filled=True, rounded=True,\n",
    "    special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_pdf(\"wine.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度： 1.0\n",
      "测试集精度： 0.972222222222\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rand_forest = RandomForestClassifier(max_depth=4)\n",
    "rand_forest.fit(x_train,y_train)\n",
    "print(\"训练集精度：\",rand_forest.score(x_train,y_train))\n",
    "print(\"测试集精度：\",rand_forest.score(x_test,y_test))\n",
    "print(rand_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=20.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "训练集精度： 0.978873239437\n",
      "测试集精度： 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(C=20.0,gamma=0.0001)\n",
    "svm.fit(x_train,y_train)\n",
    "print(svm)\n",
    "print(\"训练集精度：\",svm.score(x_train,y_train))\n",
    "print(\"测试集精度：\",svm.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度： 1.0\n",
      "测试集精度： 0.972222222222\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "net = MLPClassifier()\n",
    "net.fit(x_train,y_train)\n",
    "print(\"训练集精度：\",net.score(x_train,y_train))\n",
    "print(\"测试集精度：\",net.score(x_test,y_test))\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=13, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=60, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=60, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(13,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60,3)\n",
    ")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1170, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1130, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1090, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1051, grad_fn=<NllLossBackward>)\n",
      "tensor(1.1012, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0974, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0935, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0897, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0860, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0822, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0785, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0748, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0712, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0675, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0639, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0603, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0531, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0496, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0461, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0426, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0391, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0356, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0321, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0286, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0252, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0217, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0183, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0149, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0114, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0080, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0046, grad_fn=<NllLossBackward>)\n",
      "tensor(1.0012, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9944, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9910, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9842, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9808, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9774, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9740, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9570, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9433, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9329, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9295, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9260, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9226, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9191, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9156, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9052, grad_fn=<NllLossBackward>)\n",
      "tensor(0.9017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8982, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8912, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8841, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8806, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8664, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8264, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8153, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8116, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8079, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.8004, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7967, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7929, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7892, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7854, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7816, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7703, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7627, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7284, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7246, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7208, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7169, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7131, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7092, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7054, grad_fn=<NllLossBackward>)\n",
      "tensor(0.7015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6977, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6861, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6823, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6784, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6707, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6669, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6324, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6286, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6172, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.6022, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5910, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5873, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5799, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5689, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5653, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5617, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5581, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5438, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5367, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5332, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5297, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5263, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5228, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5193, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5125, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5091, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5057, grad_fn=<NllLossBackward>)\n",
      "tensor(0.5023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4990, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4923, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4858, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4825, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4793, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4729, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4666, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4304, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4275, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4247, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4134, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4107, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.4026, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3973, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3947, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3921, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3895, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3870, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3819, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3795, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3770, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3721, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3674, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3627, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3581, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3383, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3341, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3320, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3280, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3260, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3240, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3220, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3181, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3162, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3143, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3124, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3106, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3087, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2997, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2980, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2962, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2945, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2928, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2911, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2895, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2878, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2846, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2782, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2766, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2751, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2736, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2705, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2661, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2632, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2562, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2549, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2522, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2496, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2335, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2312, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2289, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2277, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2266, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2255, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2244, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2233, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2212, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2201, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2180, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2170, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2149, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2139, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2109, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2099, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2089, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2070, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2060, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2051, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2041, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2032, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2023, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.2005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1996, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1951, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1934, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1926, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1917, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1909, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1892, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1884, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1876, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1868, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1844, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1828, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1820, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1805, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1790, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1768, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1761, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1732, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1725, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1676, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1656, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1650, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1637, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1630, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1624, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1618, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1605, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1580, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1562, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1550, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1544, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1532, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1526, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1520, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1515, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1422, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1396, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1337, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1333, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1328, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1323, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1319, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1314, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1309, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1305, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1300, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1296, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1291, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1287, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1282, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1278, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1273, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1269, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1265, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1260, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1256, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1252, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1248, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1243, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1239, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1235, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1231, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1227, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1218, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1214, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1210, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1206, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1202, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1198, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1194, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1190, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1186, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1182, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1178, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1175, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1171, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1167, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1163, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1159, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1155, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1152, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1148, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1144, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1140, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1137, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1133, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1129, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1126, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1122, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1118, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1115, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1111, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1108, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1104, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1100, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1097, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1093, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1090, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1086, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1083, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1080, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1076, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1073, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1069, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1066, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1063, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1059, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1056, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1053, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1049, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1046, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1043, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1040, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1036, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1033, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1030, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1024, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1021, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1017, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1014, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1011, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1008, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1005, grad_fn=<NllLossBackward>)\n",
      "tensor(0.1002, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0999, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0996, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0993, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0990, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0987, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0984, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0981, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0978, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0975, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0972, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0969, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0966, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0963, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0960, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0957, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0955, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0952, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0949, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0946, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0943, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0940, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0938, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0935, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0932, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0929, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0927, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0924, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0921, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0919, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0916, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0913, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0910, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0908, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0905, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0903, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0900, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0897, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0895, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0892, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0890, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0887, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0885, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0882, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0879, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0877, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0874, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0872, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0869, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0867, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0865, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0862, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0860, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0857, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0855, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0852, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0850, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0848, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0845, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0843, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0841, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0838, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0836, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0834, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0831, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0829, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0827, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0824, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0822, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0820, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0818, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0815, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0813, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0811, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0809, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0807, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0804, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0802, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0800, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0798, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0796, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0794, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0791, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0789, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0787, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0785, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0783, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0781, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0779, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0777, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0775, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0773, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0771, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0769, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0767, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0764, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0762, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0760, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0758, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0756, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0755, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0753, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0751, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0749, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0747, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0745, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0743, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0741, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0739, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0737, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0735, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0733, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0731, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0730, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0728, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0726, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0724, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0722, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0720, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0718, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0717, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0715, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0713, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0711, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0709, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0708, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0706, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0704, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0702, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0700, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0699, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0697, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0695, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0693, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0692, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0690, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0688, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0687, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0685, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0683, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0682, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0680, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0678, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0677, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0675, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0673, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0672, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0670, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0668, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0667, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0665, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0663, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0662, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0660, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0659, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0657, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0655, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0654, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0652, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0651, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0649, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0647, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0646, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0644, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0643, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0641, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0640, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0638, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0637, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0635, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0634, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0632, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0631, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0629, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0628, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0626, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0625, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0623, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0622, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0620, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0619, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0617, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0616, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0614, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0613, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0611, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0610, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0609, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0607, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0606, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0604, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0603, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0601, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0600, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0599, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0597, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0596, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0595, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0593, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0592, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0590, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0589, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0588, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0586, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0585, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0584, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0582, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0581, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0580, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0578, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0577, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0576, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0574, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0573, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0572, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0571, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0569, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0568, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0567, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0566, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0564, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0563, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0562, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0561, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0559, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0558, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0557, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0556, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0554, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0553, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0552, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0551, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0549, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0548, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0547, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0546, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0545, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0543, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0542, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0541, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0540, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0539, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0538, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0536, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0535, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0534, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0533, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0532, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0531, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0530, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0528, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0527, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0526, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0525, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0524, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0523, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0522, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0521, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0519, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0518, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0517, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0516, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0515, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0514, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0513, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0512, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0511, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0510, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0509, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0508, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0506, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0505, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0504, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0503, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0502, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0501, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0500, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0499, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0498, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0497, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0496, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0495, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0494, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0493, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0492, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0491, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0490, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0489, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0488, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0487, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0486, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0485, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0484, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0483, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0482, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0481, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0480, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0479, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0478, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0477, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0476, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0475, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0474, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0473, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0472, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0471, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0470, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0469, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0468, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0467, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0466, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0465, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0464, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0463, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0462, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0461, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0460, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0459, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0458, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0457, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0456, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0455, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0454, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0453, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0452, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0451, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0450, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0449, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0448, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0447, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0446, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0445, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0444, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0443, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0442, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0441, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0440, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0439, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0438, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0437, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0436, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0435, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0434, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0433, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0432, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0431, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0430, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0429, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0428, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0427, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0426, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0425, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0424, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0423, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0422, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0421, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0420, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0419, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0418, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0417, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0416, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0415, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0414, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0413, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0412, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0411, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0410, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0409, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0408, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0407, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0406, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0405, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0404, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0403, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0402, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0401, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0400, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0399, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0398, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0397, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0396, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0395, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0394, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0393, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0392, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0391, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0390, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0389, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0388, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0387, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0386, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0385, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0384, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0383, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0382, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0381, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0380, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0379, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0378, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0377, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0376, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0375, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0374, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0373, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0372, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0371, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0370, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0369, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0368, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0367, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0367, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0366, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0365, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0365, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0364, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0363, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0362, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0361, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0360, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0359, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0358, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0357, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0356, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0355, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0354, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0353, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0352, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0351, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0351, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0350, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0349, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0348, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0348, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0347, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0346, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0345, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0345, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0344, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0343, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0342, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0341, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#训练数据\n",
    "for t in range(1000):\n",
    "    out = net(torch.from_numpy(x_train).float())                 # input x and predict based on x\n",
    "    loss = criterion(out, torch.from_numpy(y_train).long())     # 输出与label对比\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集预测准确率 1.0\n",
      "训练集预测准确率 0.9722222222222222\n",
      "[2 0 0 1 2 0 0 0 1 2 0 1 0 1 1 0 1 2 1 2 2 1 1 2 0 1 2 1 0 1 2 1 1 0 2 0]\n",
      "[2 0 0 1 2 0 0 0 1 2 0 1 0 1 1 0 1 2 1 2 2 1 1 2 0 1 2 1 0 2 2 1 1 0 2 0]\n"
     ]
    }
   ],
   "source": [
    "out = net(torch.from_numpy(x_train).float()) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\n",
    "prediction = torch.max(out, 1)[1] # 1返回index  0返回原值\n",
    "pred_y = prediction.data.numpy()\n",
    "target_y = y_train\n",
    "accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n",
    "print(\"训练集预测准确率\",accuracy)\n",
    "X_test=torch.FloatTensor(x_test)\n",
    "y_test=torch.LongTensor(y_test)\n",
    "out = net(X_test) #out是一个计算矩阵，可以用Fun.softmax(out)转化为概率矩阵\n",
    "prediction = torch.max(out, 1)[1] # 1返回index  0返回原值\n",
    "pred_y = prediction.data.numpy()\n",
    "target_y = y_test.data.numpy()\n",
    "accuracy = float((pred_y == target_y).astype(int).sum()) / float(target_y.size)\n",
    "print(\"训练集预测准确率\",accuracy)\n",
    "print(pred_y)\n",
    "print(target_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Data Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- 1) Alcohol\n",
      " \t\t- 2) Malic acid\n",
      " \t\t- 3) Ash\n",
      "\t\t- 4) Alcalinity of ash  \n",
      " \t\t- 5) Magnesium\n",
      "\t\t- 6) Total phenols\n",
      " \t\t- 7) Flavanoids\n",
      " \t\t- 8) Nonflavanoid phenols\n",
      " \t\t- 9) Proanthocyanins\n",
      "\t\t- 10)Color intensity\n",
      " \t\t- 11)Hue\n",
      " \t\t- 12)OD280/OD315 of diluted wines\n",
      " \t\t- 13)Proline\n",
      "        \t- class:\n",
      "                - class_0\n",
      "                - class_1\n",
      "                - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      "References\n",
      "----------\n",
      "(1) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "Comparison of Classifiers in High Dimensional Settings, \n",
      "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Technometrics). \n",
      "\n",
      "The data was used with many others for comparing various \n",
      "classifiers. The classes are separable, though only RDA \n",
      "has achieved 100% correct classification. \n",
      "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "(All results using the leave-one-out technique) \n",
      "\n",
      "(2) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "\"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Journal of Chemometrics). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
